{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348c4a35",
   "metadata": {},
   "source": [
    "# AB Testing Final Project Udacity\n",
    "project description: https://docs.google.com/document/u/1/d/1aCquhIqsUApgsxQ8-SQBAigFDcfWVVohLEXcV6jWbdI/pub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0e1ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38bc38fc",
   "metadata": {},
   "source": [
    "## Import module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19adffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47921b48",
   "metadata": {},
   "source": [
    "# 1. Metric Choice\n",
    "> See readme.md - https://github.com/Wei-Kuang/Udacity_AB_Testing_Final_Project#readme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d193c",
   "metadata": {},
   "source": [
    "# 2. Measuring Variability\n",
    "This **spreadsheet** (see the DF-dataframe that I created) contains rough estimates of the baseline values for these metrics (again, these numbers have been changed from Udacity's true numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edbade6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metirc</th>\n",
       "      <th>alias</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unique cookies to view course overview page per day</td>\n",
       "      <td>n_pageview</td>\n",
       "      <td>40000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unique cookies to click \"Start free trial\" per day</td>\n",
       "      <td>n_click</td>\n",
       "      <td>3200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enrollments per day</td>\n",
       "      <td>n_enroll</td>\n",
       "      <td>660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Click-through-probability on \"Start free trial\"</td>\n",
       "      <td>p_click</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Probability of enrolling, given click</td>\n",
       "      <td>p_enroll_click</td>\n",
       "      <td>0.206250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probability of payment, given enroll</td>\n",
       "      <td>p_payment_enroll</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Probability of payment, given click</td>\n",
       "      <td>p_payment_click</td>\n",
       "      <td>0.109313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                metirc             alias  \\\n",
       "0  Unique cookies to view course overview page per day        n_pageview   \n",
       "1   Unique cookies to click \"Start free trial\" per day           n_click   \n",
       "2                                  Enrollments per day          n_enroll   \n",
       "3      Click-through-probability on \"Start free trial\"           p_click   \n",
       "4                Probability of enrolling, given click    p_enroll_click   \n",
       "5                 Probability of payment, given enroll  p_payment_enroll   \n",
       "6                  Probability of payment, given click   p_payment_click   \n",
       "\n",
       "          value  \n",
       "0  40000.000000  \n",
       "1   3200.000000  \n",
       "2    660.000000  \n",
       "3      0.080000  \n",
       "4      0.206250  \n",
       "5      0.530000  \n",
       "6      0.109313  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dict = {\n",
    "    \"metirc\":['Unique cookies to view course overview page per day', \n",
    "              'Unique cookies to click \"Start free trial\" per day', \n",
    "              'Enrollments per day',  \n",
    "              'Click-through-probability on \"Start free trial\"', \n",
    "              'Probability of enrolling, given click',  \n",
    "              'Probability of payment, given enroll', \n",
    "              'Probability of payment, given click']\n",
    "    \n",
    "    ,\"alias\":['n_pageview', 'n_click', 'n_enroll', 'p_click', 'p_enroll_click' , 'p_payment_enroll','p_payment_click']\n",
    "    \n",
    "    ,\"value\": [40000,3200,660,0.08,0.20625, 0.53, 0.1093125]\n",
    "}\n",
    "\n",
    "pd.set_option('display.max_colwidth', None) # display all content\n",
    "DF = pd.DataFrame(x_dict)\n",
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96548aef",
   "metadata": {},
   "source": [
    "For each metric **you selected as an evaluation metric**, estimate its **standard deviation** analytically, given that the sample size is 5000 cookies visiting course overview page. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88efd6c",
   "metadata": {},
   "source": [
    "### Evaluation metrics\n",
    "I select three evaluation metrics and their **baseline value**:\n",
    "1. Gross conversion = enrollment / click = probability of enrolling, given click = **0.20625**\n",
    "2. Retention = payment / enrollment = probability of payment, given enroll = **0.53**\n",
    "3. Net conversion = payment / click = probability of payment, given click  = **0.109313**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17084212",
   "metadata": {},
   "source": [
    "### To calculate the analytic standard deviation for the evaluation metrics, given that page views = 5000\n",
    "\n",
    "My thinking process:  \n",
    "1. Basically, this is a scale-down process.\n",
    "\n",
    "\n",
    "2. The baseline info is based on sample size = 40000 (page views). Now, we need to re-estimate the statistics given the sample size = 5000.\n",
    "\n",
    "\n",
    "3. Probability's standard error (SE):\n",
    "\n",
    "$ SE = \\sqrt{P(1-P) \\over N}  $\n",
    "\n",
    "4. The key is to find \"N (denominator)\" for each evaluation metric, given that page view = 5000. That is, we need to figure out **n_click** and **n_enroll**.\n",
    "\n",
    "\n",
    "5. In other words, let's solve these two equations to figure the click and enrollment, given page view = 5000.\n",
    "\n",
    "$$  {3200 \\over 40000} = { click \\over 5000}  $$\n",
    "\n",
    "$$  {660 \\over 40000} = { enroll \\over 5000}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55fa5b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of Clikc: 400.0\n",
      "N of Enrollment:  82.5\n",
      "Given that course paveview = 5000\n"
     ]
    }
   ],
   "source": [
    "# Data given pageview = 5000\n",
    "n_Click   = (3200 * 5000 ) /40000\n",
    "n_Entroll = (660 * 5000 ) /40000\n",
    "\n",
    "# computation result given page view = 5000\n",
    "print('N of Clikc:', n_Click)\n",
    "print('N of Enrollment: ', n_Entroll)\n",
    "print('Given that course paveview = 5000')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56cd1c",
   "metadata": {},
   "source": [
    "### Calculate the analytic standard error,  given that page view = 500\n",
    "\n",
    "Let's use analytic form to compute probability's standard deviation (SD):\n",
    "\n",
    "$ Se = \\sqrt{P(1-P) \\over N}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7015d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_sd(p,n):\n",
    "    import math\n",
    "    sd = math.sqrt(  ( p*(1-p) /n ) )\n",
    "    return round(sd, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce9e93",
   "metadata": {},
   "source": [
    "#### SE - Gross Conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9186ab52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0202"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability of enrolling, given click = 0.206250\n",
    "# n_click= 400, given the page view = 5000\n",
    "get_prob_sd(p=0.20625, n = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b413f0d",
   "metadata": {},
   "source": [
    "#### SE - Retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67cc6f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0549"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability of payment, given enroll = 0.530000\n",
    "# N of enrolling = 82.5 , given pageview = 5000 \n",
    "get_prob_sd(p=0.53, n = 82.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345587e1",
   "metadata": {},
   "source": [
    "#### SE - Net Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee1e4e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0156"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NC =  (n of payment) / n_click = Probability of payment, given click = 0.109313\n",
    "# n_click= 400, given the page view = 5000\n",
    "get_prob_sd(p=0.109313, n = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad86153e",
   "metadata": {},
   "source": [
    "**Summary of Variability**\n",
    "\n",
    "The estimated variability is based on the page view = 5000. This will give us an ideal which metric might be problematic.\n",
    "\n",
    "|Metric| Standard Error|\n",
    "|---   |                ---|\n",
    "|Gross Conversion|0.0202|\n",
    "|Retention       |0.0549|\n",
    "|Net Conversion  |0.0156|\n",
    "\n",
    "> **Note:** Retention's SE is relatively large. We will take a look if we can collect enough data to overcome this large variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cfdc46",
   "metadata": {},
   "source": [
    "**Question:** Do you expect the analytic estimates to be accurate? That is, for which metrics, if any, would you want to collect an empirical estimate of the variability if you had time?\n",
    "\n",
    "> **My answer:** \n",
    "I would like to collect empirical estimates of variability for (1) **Gross Conversion** and (2) **Net Conversion**, because for these metrics, their unit of diversion is not the same as the unit of analysis. In such case, the analytic form of variability is usually underestimated (smaller than the truth). Thus, it's better to use bootstrap method to obtain the empirical estimate of the variability. \n",
    "\n",
    "\n",
    "|Evaluation metric | Numerator (unit of diversion) | Denominator (unit of analysis)  |\n",
    "|------------------|-------------------------------|---------------------------------|\n",
    "|Gross Conversion  | enrollment (user-id)          | click (cookie)                  |\n",
    "|Retention         | payment (user-id)             | enroll (user-id)                |\n",
    "|Net Conversion    | payment (user-id)             | click (cookie)                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e2a0d",
   "metadata": {},
   "source": [
    "# 3.  Sizing vs. Duration vs. Exposure\n",
    "\n",
    "### Choosing Number of Samples given Power\n",
    "Using the analytic estimates of variance, how many page views total (across both groups) would you need to collect to adequately power the experiment? Use an alpha of 0.05 and a beta of 0.2. Make sure you have enough power for each metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b14c7",
   "metadata": {},
   "source": [
    "#### My thinking process:  \n",
    "1. I will compute the required sample size for each evaluation metric, based on the (1) baseline data, (2) minimally important difference (dmin) , (3) alpha = 0.05, and (4) beta=0.2.\n",
    "\n",
    "2. On-line calculator will be a great tool for this task: https://www.evanmiller.org/ab-testing/sample-size.html\n",
    "\n",
    "3. Convert the required \"sample size\" into required \"page views\" for both control and experiment groups.\n",
    "\n",
    "4. Then, check if our system can reach the sample size in a short time (usually ~ 30 days). If a metric need more than 30 days to collect, we might need to drop it or re-design the experiment.\n",
    "\n",
    "5. Based on the required page views, I will select the maximum page views among evaluation metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52c119",
   "metadata": {},
   "source": [
    "#### Size  -  Gross Conversion \n",
    "* dmin = 0.01\n",
    "\n",
    "* GC = n_enroll / n_click  = Probability of enrolling, given click  = 0.206250 (baseline)\n",
    "\n",
    "* Required Sample Size in each group, N=25835 (using Online-calculator).\n",
    "\n",
    "* Required n-click (two groups) = 2 * 25835 = 51670\n",
    "\n",
    "* Then, we want to know how many page view can reach the number of required clicks.\n",
    "\n",
    "* Based on the ratio, there will be 3,200 clicks among 40000 page views.\n",
    "\n",
    "* Now, we need to have [2*25835 = 51,670] clicks, so  we need  (40000 * 51670) / (3200)  = 645,875 page views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c15a099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645875.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_Click_both_group = 2*25835\n",
    "N_Pageview = (N_Click_both_group * 40000) /3200\n",
    "N_Pageview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a93e3f",
   "metadata": {},
   "source": [
    "#### Size - Retention\n",
    "* dmin = 0.01\n",
    "* RT = (n of payment) / n_enroll = Probability of payment, given enroll = 0.530000\n",
    "* Required Sample Size in each group, N=39115 (using Online-calculator).\n",
    "* Two groups of required enrollments = 2 * 39115 = 78230\n",
    "* Based on the ratio, there will be 660 enrollments given 40000 page views.\n",
    "* Thus, to reach 78,230 enrollments, then we need 4,741,212 page view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6bc72fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4741212.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_Enrol_two_groups = 2*39115\n",
    "N_Pageview = (N_Enrol_two_groups * 40000)/660\n",
    "round(N_Pageview,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f3c9b3",
   "metadata": {},
   "source": [
    "#### Size - Net Conversion\n",
    "* dmin = 0.0075\n",
    "* NC =  (n of payment) / n_click = Probability of payment, given click = 0.109313\n",
    "* Required Sample Size in each group, N=27,413 (using Online-calculator).\n",
    "* Two groups of required n-click = 2 * 27413 = 54,826\n",
    "* Based on the ratio, there will be 3,200 clicks given 40000 page views.\n",
    "* Now, we need to have 2 * 27413 = 54,826 clicks, we need 685,325 page views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a8a68d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685325.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_Click_two_groups = 2*27413\n",
    "N_Pageview = (N_Click_two_groups * 40000)/3200\n",
    "N_Pageview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a3f09",
   "metadata": {},
   "source": [
    "#### How many days are enough to reach the required the page views for each evaluation metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b31e5500",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gross Conversion:  33  days, using 50% traffic\n",
      "Retention:         238  days, using 50% traffic\n",
      "Net Conversion:    35  days, using 50% traffic\n",
      "\n",
      "\n",
      "Gross Conversion:  17  days, using 100% traffic\n",
      "Retention:         119  days, using 100% traffic\n",
      "Net Conversion:    18  days, using 100% traffic\n"
     ]
    }
   ],
   "source": [
    "print('Gross Conversion: '  ,  math.ceil(645875/(40000*0.5)  ),  ' days, using 50% traffic' )\n",
    "print('Retention:        '  ,  math.ceil(4741212/(40000*0.5) ),  ' days, using 50% traffic' )\n",
    "print('Net Conversion:   '  ,  math.ceil(685325/(40000*0.5)  ),  ' days, using 50% traffic' )\n",
    "print('\\n')\n",
    "print('Gross Conversion: '  ,  math.ceil(645875/(40000*1.00)  ),  ' days, using 100% traffic' )\n",
    "print('Retention:        '  ,  math.ceil(4741212/(40000*1.00) ),  ' days, using 100% traffic' )\n",
    "print('Net Conversion:   '  ,  math.ceil(685325/(40000*1.00)  ),  ' days, using 100% traffic' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d895b0ab",
   "metadata": {},
   "source": [
    "**Summary of Sizing**\n",
    "\n",
    "* This is the sample size to reach these wanted statistics parameters: 0.05 alpha (Type I error) and 0.2 Beta (Type II error)\n",
    "* With 100% traffic, the site estimated that there will be 40000 page views per day.\n",
    "\n",
    "|Metrics| Required page view (cookies)| Required days with 50% traffic | Required days with 100% traffic |\n",
    "|-|-|-|-|\n",
    "|Gross Conversion| 645,875|33 days| 17 days|\n",
    "|Retention|4,741,212|238 days|119 days|\n",
    "|Net Conversion|685,325|35 days|18 days|\n",
    "\n",
    "> Note: Retention need 119 days (17 weeks =~ 4 months) to obtain wanted sample size, even if we use 100% of the traffic. This is too long for a on-line experiment. I will drop \"Retention\" from the list of evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd5a3ec",
   "metadata": {},
   "source": [
    "**Question:** Which evaluation metrics did you choose?\n",
    "\n",
    "> **ANS:** (1) gross conversion and (2) net conversion\n",
    "\n",
    "\n",
    "**Question:** Will you use Bonferroni Correction? \n",
    "\n",
    "> **ANS:** These evaluation metrics are highly correlated, so Bonferroni would be too conservative.\n",
    "\n",
    "\n",
    "**Question:** Is the change risky enough that you wouldn't want to run on all traffic?\n",
    "\n",
    "> **ANS:** The feature is to add additional question to ask users about the commitment time and then it diverts users into different processes. I think this new feature is not very risky, because this feature just adds an additional branching of the process, instead of changing an entire new user funnel process. \n",
    "\n",
    "\n",
    "\n",
    "**Question:** What percentage of Udacity's traffic would you divert to this experiment (assuming there were no other experiments you wanted to run simultaneously)?\n",
    " \n",
    "> **ANS:** Just to be safe, we can use the 90% of traffic. \n",
    "\n",
    "**Question:** How many page view that we need? \n",
    "\n",
    "> **ANS** 685,325 which is the maximum required page views among (1) gross conversion and (2) net conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e47de",
   "metadata": {},
   "source": [
    "## 4. Data\n",
    "The data for you to analyze is here. This data contains the raw information needed to compute the above metrics, broken down day by day. Note that there are two sheets within the spreadsheet - one for the experiment group, and one for the control group.\n",
    "\n",
    "\n",
    "#### Column definition:\n",
    "\n",
    "* **Page views:** Number of unique cookies to view the course overview page that day.\n",
    "\n",
    "* **Clicks:** Number of unique cookies to click the course overview page that day.\n",
    "\n",
    "* **Enrollments:** Number of user-ids to enroll in the free trial that day.\n",
    "\n",
    "* **Payments:** Number of user-ids who who enrolled on that day to remain enrolled for 14 days and thus make a payment. (Note that the date for this column is the start date, that is, the date of enrollment, rather than the date of the payment. The payment happened 14 days later. Because of this, the enrollments and payments are tracked for 14 fewer days than the other columns.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23eca6a",
   "metadata": {},
   "source": [
    "#### Control Group Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a4e7368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7723.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9102.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10511.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9871.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>10014.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thu, Oct 16</td>\n",
       "      <td>9670.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fri, Oct 17</td>\n",
       "      <td>9008.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sat, Oct 18</td>\n",
       "      <td>7434.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sun, Oct 19</td>\n",
       "      <td>8459.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mon, Oct 20</td>\n",
       "      <td>10667.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tue, Oct 21</td>\n",
       "      <td>10660.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wed, Oct 22</td>\n",
       "      <td>9947.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thu, Oct 23</td>\n",
       "      <td>8324.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fri, Oct 24</td>\n",
       "      <td>9434.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sat, Oct 25</td>\n",
       "      <td>8687.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sun, Oct 26</td>\n",
       "      <td>8896.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mon, Oct 27</td>\n",
       "      <td>9535.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tue, Oct 28</td>\n",
       "      <td>9363.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wed, Oct 29</td>\n",
       "      <td>9327.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Thu, Oct 30</td>\n",
       "      <td>9345.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fri, Oct 31</td>\n",
       "      <td>8890.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sat, Nov 1</td>\n",
       "      <td>8460.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sun, Nov 2</td>\n",
       "      <td>8836.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mon, Nov 3</td>\n",
       "      <td>9437.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tue, Nov 4</td>\n",
       "      <td>9420.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Wed, Nov 5</td>\n",
       "      <td>9570.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Thu, Nov 6</td>\n",
       "      <td>9921.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fri, Nov 7</td>\n",
       "      <td>9424.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sat, Nov 8</td>\n",
       "      <td>9010.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sun, Nov 9</td>\n",
       "      <td>9656.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mon, Nov 10</td>\n",
       "      <td>10419.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Tue, Nov 11</td>\n",
       "      <td>9880.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Wed, Nov 12</td>\n",
       "      <td>10134.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Thu, Nov 13</td>\n",
       "      <td>9717.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fri, Nov 14</td>\n",
       "      <td>9192.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sat, Nov 15</td>\n",
       "      <td>8630.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sun, Nov 16</td>\n",
       "      <td>8970.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Pageviews  Clicks  Enrollments  Payments\n",
       "0   Sat, Oct 11     7723.0   687.0        134.0      70.0\n",
       "1   Sun, Oct 12     9102.0   779.0        147.0      70.0\n",
       "2   Mon, Oct 13    10511.0   909.0        167.0      95.0\n",
       "3   Tue, Oct 14     9871.0   836.0        156.0     105.0\n",
       "4   Wed, Oct 15    10014.0   837.0        163.0      64.0\n",
       "5   Thu, Oct 16     9670.0   823.0        138.0      82.0\n",
       "6   Fri, Oct 17     9008.0   748.0        146.0      76.0\n",
       "7   Sat, Oct 18     7434.0   632.0        110.0      70.0\n",
       "8   Sun, Oct 19     8459.0   691.0        131.0      60.0\n",
       "9   Mon, Oct 20    10667.0   861.0        165.0      97.0\n",
       "10  Tue, Oct 21    10660.0   867.0        196.0     105.0\n",
       "11  Wed, Oct 22     9947.0   838.0        162.0      92.0\n",
       "12  Thu, Oct 23     8324.0   665.0        127.0      56.0\n",
       "13  Fri, Oct 24     9434.0   673.0        220.0     122.0\n",
       "14  Sat, Oct 25     8687.0   691.0        176.0     128.0\n",
       "15  Sun, Oct 26     8896.0   708.0        161.0     104.0\n",
       "16  Mon, Oct 27     9535.0   759.0        233.0     124.0\n",
       "17  Tue, Oct 28     9363.0   736.0        154.0      91.0\n",
       "18  Wed, Oct 29     9327.0   739.0        196.0      86.0\n",
       "19  Thu, Oct 30     9345.0   734.0        167.0      75.0\n",
       "20  Fri, Oct 31     8890.0   706.0        174.0     101.0\n",
       "21   Sat, Nov 1     8460.0   681.0        156.0      93.0\n",
       "22   Sun, Nov 2     8836.0   693.0        206.0      67.0\n",
       "23   Mon, Nov 3     9437.0   788.0          NaN       NaN\n",
       "24   Tue, Nov 4     9420.0   781.0          NaN       NaN\n",
       "25   Wed, Nov 5     9570.0   805.0          NaN       NaN\n",
       "26   Thu, Nov 6     9921.0   830.0          NaN       NaN\n",
       "27   Fri, Nov 7     9424.0   781.0          NaN       NaN\n",
       "28   Sat, Nov 8     9010.0   756.0          NaN       NaN\n",
       "29   Sun, Nov 9     9656.0   825.0          NaN       NaN\n",
       "30  Mon, Nov 10    10419.0   874.0          NaN       NaN\n",
       "31  Tue, Nov 11     9880.0   830.0          NaN       NaN\n",
       "32  Wed, Nov 12    10134.0   801.0          NaN       NaN\n",
       "33  Thu, Nov 13     9717.0   814.0          NaN       NaN\n",
       "34  Fri, Nov 14     9192.0   735.0          NaN       NaN\n",
       "35  Sat, Nov 15     8630.0   743.0          NaN       NaN\n",
       "36  Sun, Nov 16     8970.0   722.0          NaN       NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Ctrl = pd.read_excel(\"C:/Users/15177/Desktop/Learn_Analysis/AB_Test_Udacity/Final_Project_Results.xlsx\", sheet_name=\"Control\")\n",
    "df_Ctrl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde5679",
   "metadata": {},
   "source": [
    "> Note: There are missing values starting at row-23 for Enrollment and Payments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f88eb2",
   "metadata": {},
   "source": [
    "#### Experiment Group Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59118809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7716.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9288.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10480.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9867.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>9793.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thu, Oct 16</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fri, Oct 17</td>\n",
       "      <td>9088.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sat, Oct 18</td>\n",
       "      <td>7664.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sun, Oct 19</td>\n",
       "      <td>8434.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mon, Oct 20</td>\n",
       "      <td>10496.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tue, Oct 21</td>\n",
       "      <td>10551.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wed, Oct 22</td>\n",
       "      <td>9737.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thu, Oct 23</td>\n",
       "      <td>8176.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fri, Oct 24</td>\n",
       "      <td>9402.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sat, Oct 25</td>\n",
       "      <td>8669.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sun, Oct 26</td>\n",
       "      <td>8881.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mon, Oct 27</td>\n",
       "      <td>9655.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tue, Oct 28</td>\n",
       "      <td>9396.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wed, Oct 29</td>\n",
       "      <td>9262.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Thu, Oct 30</td>\n",
       "      <td>9308.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fri, Oct 31</td>\n",
       "      <td>8715.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sat, Nov 1</td>\n",
       "      <td>8448.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sun, Nov 2</td>\n",
       "      <td>8836.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mon, Nov 3</td>\n",
       "      <td>9359.0</td>\n",
       "      <td>789.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tue, Nov 4</td>\n",
       "      <td>9427.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Wed, Nov 5</td>\n",
       "      <td>9633.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Thu, Nov 6</td>\n",
       "      <td>9842.0</td>\n",
       "      <td>831.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fri, Nov 7</td>\n",
       "      <td>9272.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sat, Nov 8</td>\n",
       "      <td>8969.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sun, Nov 9</td>\n",
       "      <td>9697.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mon, Nov 10</td>\n",
       "      <td>10445.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Tue, Nov 11</td>\n",
       "      <td>9931.0</td>\n",
       "      <td>831.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Wed, Nov 12</td>\n",
       "      <td>10042.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Thu, Nov 13</td>\n",
       "      <td>9721.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fri, Nov 14</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sat, Nov 15</td>\n",
       "      <td>8668.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sun, Nov 16</td>\n",
       "      <td>8988.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Pageviews  Clicks  Enrollments  Payments\n",
       "0   Sat, Oct 11     7716.0   686.0        105.0      34.0\n",
       "1   Sun, Oct 12     9288.0   785.0        116.0      91.0\n",
       "2   Mon, Oct 13    10480.0   884.0        145.0      79.0\n",
       "3   Tue, Oct 14     9867.0   827.0        138.0      92.0\n",
       "4   Wed, Oct 15     9793.0   832.0        140.0      94.0\n",
       "5   Thu, Oct 16     9500.0   788.0        129.0      61.0\n",
       "6   Fri, Oct 17     9088.0   780.0        127.0      44.0\n",
       "7   Sat, Oct 18     7664.0   652.0         94.0      62.0\n",
       "8   Sun, Oct 19     8434.0   697.0        120.0      77.0\n",
       "9   Mon, Oct 20    10496.0   860.0        153.0      98.0\n",
       "10  Tue, Oct 21    10551.0   864.0        143.0      71.0\n",
       "11  Wed, Oct 22     9737.0   801.0        128.0      70.0\n",
       "12  Thu, Oct 23     8176.0   642.0        122.0      68.0\n",
       "13  Fri, Oct 24     9402.0   697.0        194.0      94.0\n",
       "14  Sat, Oct 25     8669.0   669.0        127.0      81.0\n",
       "15  Sun, Oct 26     8881.0   693.0        153.0     101.0\n",
       "16  Mon, Oct 27     9655.0   771.0        213.0     119.0\n",
       "17  Tue, Oct 28     9396.0   736.0        162.0     120.0\n",
       "18  Wed, Oct 29     9262.0   727.0        201.0      96.0\n",
       "19  Thu, Oct 30     9308.0   728.0        207.0      67.0\n",
       "20  Fri, Oct 31     8715.0   722.0        182.0     123.0\n",
       "21   Sat, Nov 1     8448.0   695.0        142.0     100.0\n",
       "22   Sun, Nov 2     8836.0   724.0        182.0     103.0\n",
       "23   Mon, Nov 3     9359.0   789.0          NaN       NaN\n",
       "24   Tue, Nov 4     9427.0   743.0          NaN       NaN\n",
       "25   Wed, Nov 5     9633.0   808.0          NaN       NaN\n",
       "26   Thu, Nov 6     9842.0   831.0          NaN       NaN\n",
       "27   Fri, Nov 7     9272.0   767.0          NaN       NaN\n",
       "28   Sat, Nov 8     8969.0   760.0          NaN       NaN\n",
       "29   Sun, Nov 9     9697.0   850.0          NaN       NaN\n",
       "30  Mon, Nov 10    10445.0   851.0          NaN       NaN\n",
       "31  Tue, Nov 11     9931.0   831.0          NaN       NaN\n",
       "32  Wed, Nov 12    10042.0   802.0          NaN       NaN\n",
       "33  Thu, Nov 13     9721.0   829.0          NaN       NaN\n",
       "34  Fri, Nov 14     9304.0   770.0          NaN       NaN\n",
       "35  Sat, Nov 15     8668.0   724.0          NaN       NaN\n",
       "36  Sun, Nov 16     8988.0   710.0          NaN       NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Exp = pd.read_excel(\"C:/Users/15177/Desktop/Learn_Analysis/AB_Test_Udacity/Final_Project_Results.xlsx\", sheet_name=\"Experiment\")\n",
    "df_Exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62838348",
   "metadata": {},
   "source": [
    "> Note: There are missing values starting at row-23 for Enrollment and Payments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e31919",
   "metadata": {},
   "source": [
    "## 5. Sanity Check\n",
    "Checking whether your invariant metrics are equivalent between the Control and Experiment groups. \n",
    "\n",
    "Here are my invariant metrics:\n",
    "* Number of cookies (simple count)\n",
    "* Number of clicks (simple count)\n",
    "* Click-through-probability (probability)\n",
    "\n",
    "\n",
    "Hints:\n",
    "> If the invariant metric is a **simple count** that should be randomly split between the 2 groups, you can use a **binomial test** as demonstrated in Lesson 5. Otherwise, you will need to construct a **confidence interval** for a **difference in proportions** using a similar strategy as in Lesson 1, then check whether the difference between group values falls within that confidence level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb029d",
   "metadata": {},
   "source": [
    "## Sanity Check: [1] Number of cookies\n",
    "**Note:** Page view is tracked by cookies.  Thus, the invariant metric (the number of cookies) = the number of page view."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc01796",
   "metadata": {},
   "source": [
    "**My thinking process for Sign Test (Binomial test) :** \n",
    "1. Page view is a simple count, so I can use Sign Test (Binomial test) to perform the sanity check. \n",
    "\n",
    "\n",
    "2. The key is to realize each day is an independent trial and the success can be defined as \"Control > Experiment\". \n",
    "\n",
    "\n",
    "3. The assumption is that **page views** should be equally and randomly divided into two groups. Therefore, some days Control group may have more page view than Experiment group, and this chance is expected to be 0.5. \n",
    "\n",
    "\n",
    "4. Then, the \"binomial test\" will test if the observed data match our expectation. In this case, if p-value > 0.05, then this is the statistical evidence to support no difference between two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8555fc",
   "metadata": {},
   "source": [
    "**My thinking process for using Confidence interval to perform sanity check :** \n",
    "1. The assumption is that the page views should be equally and randomly divided into two groups, so the the ratio of Control to Experiment should be close to 1:1 or we can say p = (N of Control)/(total) is about 0.5.\n",
    "\n",
    "\n",
    "2. The strategy is to obtain the 95% confidence interval (95%CI) on the expected p, given the expected p=0.5 and observed N.\n",
    "\n",
    "\n",
    "3. The decision-making process is that if the observed $ \\hat{p} $ is in this 95%CI, then sanity check pass! , because it's acceptable to observe such $ \\hat{p} $ at the 95% confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f708193c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_trials:  37\n",
      "N_success:  22\n",
      "Sing Test (two-sided) P-value:  0.324009\n",
      "\n",
      "Conclusion: Sing Test (two-sided) P-value:  0.324009 > 0.05, so we fail to reject Null hypothesis. We support that there is no difference. Sanity Check passes!\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "#### Sign Test for Page views ####\n",
    "##################################\n",
    "from scipy import stats\n",
    "N_trials = len(df_Ctrl['Pageviews']) \n",
    "N_success = sum( df_Ctrl['Pageviews'] > df_Exp['Pageviews'])\n",
    "p_value_SingTest = stats.binom_test(x=N_success, n=N_trials, p=0.5, alternative='two-sided')\n",
    "p_value_SingTest = round(p_value_SingTest,6)\n",
    "\n",
    "# Sign Test Result\n",
    "print( \"N_trials: \", N_trials)\n",
    "print( \"N_success: \", N_success)\n",
    "print( \"Sing Test (two-sided) P-value: \", p_value_SingTest)\n",
    "print('')\n",
    "print('Conclusion: Sing Test (two-sided) P-value:  0.324009 > 0.05, so we fail to reject Null hypothesis. We support that there is no difference. Sanity Check passes!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d85d4b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE                                               0.0006\n",
      "95% Confidence interval on expected probability  [0.4988, 0.5012]\n",
      "Observed probability                             0.5006\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "#### Using CI to perform Sanity Check ####\n",
    "##########################################\n",
    "N_cookies_Ctrl = df_Ctrl['Pageviews'].sum()\n",
    "N_cookies_Exp = df_Exp['Pageviews'].sum()\n",
    "\n",
    "# Compute the 95% CI for the value that we expect to observe. Thus, the SE is based on p = 0.5 \n",
    "N = N_cookies_Ctrl+N_cookies_Exp\n",
    "SE_expected = math.sqrt( 0.5 * (1-0.5) * (1/N))\n",
    "SE_expected = round(SE_expected, 4)\n",
    "\n",
    "# 95% CI for the value that we expect to observe \n",
    "margin_error = 1.96* SE_expected\n",
    "CI95_expected = [0.5-margin_error, 0.5 + margin_error]\n",
    "CI95_expected = [round(i,4) for i in CI95_expected]\n",
    "\n",
    "# observed probability\n",
    "P_Obs = N_cookies_Ctrl / (N_cookies_Ctrl+N_cookies_Exp)\n",
    "P_Obs = round(P_Obs,4)\n",
    "\n",
    "# Result\n",
    "print('SE                                              ', SE_expected)\n",
    "print('95% Confidence interval on expected probability ', CI95_expected)\n",
    "print('Observed probability                            ', P_Obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600a9adb",
   "metadata": {},
   "source": [
    "**Result of Sanity Check: Number of cookies**\n",
    "* Sanity Check passes!\n",
    "* Since the observed probability (0.5006) is in the expected 95%CI [0.4988, 0.5012], this matches our expectation. \n",
    "* Sign test (binomial test)also agrees with this conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2316b",
   "metadata": {},
   "source": [
    "## Sanity Check: [2] Number of clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0232941c",
   "metadata": {},
   "source": [
    "**My thinking process for using Sign Test:**\n",
    "1. The number of clicks is a simple count, so I can use Sign Test (Binomial test) to perform the sanity check. \n",
    "\n",
    "\n",
    "2. The key is to realize each day is an independent trial and the success can be defined as \"Control > Experiment\". \n",
    "\n",
    "\n",
    "3. The assumption is that **clicks** should be equally and randomly divided into two groups. Therefore, some days Control group may have more page view than Experiment group, and this chance is expected to be 0.5. \n",
    "\n",
    "\n",
    "4. Then, the \"binomial test\" will test if the observed data match our expectation. In this case, if p-value > 0.05, then this is the statistical evidence to support no difference between two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a1f5fd",
   "metadata": {},
   "source": [
    "**My thinking process for using Confidence interval to perform sanity check :** \n",
    "1. The assumption is that the clicks should be equally and randomly divided into two groups, so the the ratio of Control to Experiment should be close to 1:1 or we can say p = (N of Control)/(total) is about 0.5.\n",
    "\n",
    "\n",
    "2. The strategy is to obtain the 95% confidence interval (95%CI) on the expected p, given the expected p=0.5 and observed N.\n",
    "\n",
    "\n",
    "3. The decision-making process is that if the observed $ \\hat{p} $ is in this 95%CI, then sanity check pass! , because it's acceptable to observe such $ \\hat{p} $ at the 95% confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e7ef97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_trials:  37\n",
      "N_success:  18\n",
      "Sing Test (two-sided) P-value:  1.0\n",
      "\n",
      "Conclusion: Sing Test (two-sided) P-value:  1.0 > 0.05, so we fail to reject Null hypothesis. We support that there is no difference. Sanity Check passes!\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#### Sign Test for clicks ####\n",
    "##############################\n",
    "from scipy import stats\n",
    "\n",
    "N_trials = len(df_Ctrl['Clicks']) \n",
    "N_success = sum( df_Ctrl['Clicks'] > df_Exp['Clicks'])\n",
    "\n",
    "p_value_SingTest = stats.binom_test(x=N_success, n=N_trials, p=0.5, alternative='two-sided')\n",
    "p_value_SingTest = round(p_value_SingTest,6)\n",
    "\n",
    "print( \"N_trials: \", N_trials)\n",
    "print( \"N_success: \", N_success)\n",
    "print( \"Sing Test (two-sided) P-value: \", p_value_SingTest)\n",
    "print('')\n",
    "print( 'Conclusion: Sing Test (two-sided) P-value:  1.0 > 0.05, so we fail to reject Null hypothesis. We support that there is no difference. Sanity Check passes!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37c50c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE                                               0.0021\n",
      "95% Confidence interval on expected probability  [0.4959, 0.5041]\n",
      "Observed probability                             0.5005\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "#### Using CI to perform Sanity Check ####\n",
    "##########################################\n",
    "N_clicks_Ctrl = df_Ctrl['Clicks'].sum()\n",
    "N_clicks_Exp = df_Exp['Clicks'].sum()\n",
    "\n",
    "# Compute the 95% CI for the value that we expect to observe \n",
    "# Thus, the SE is based on p = 0.5 \n",
    "N = N_clicks_Ctrl+N_clicks_Exp\n",
    "SE_expected = math.sqrt( 0.5 * (1-0.5) * (1/N))\n",
    "SE_expected = round(SE_expected, 4)\n",
    "\n",
    "# 95% CI for the value that we expect to observe \n",
    "margin_error = 1.96* SE_expected\n",
    "CI95_expected = [0.5-margin_error, 0.5 + margin_error]\n",
    "CI95_expected = [round(i,4) for i in CI95_expected]\n",
    "\n",
    "# observed probability\n",
    "\n",
    "P_Obs = N_clicks_Ctrl / (N_clicks_Ctrl+N_clicks_Exp)\n",
    "P_Obs = round(P_Obs,4)\n",
    "\n",
    "# Result\n",
    "print('SE                                              ', SE_expected)\n",
    "print('95% Confidence interval on expected probability ', CI95_expected)\n",
    "print('Observed probability                            ', P_Obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241708ae",
   "metadata": {},
   "source": [
    "**Sanity Check Result - Number of Clicks**\n",
    "\n",
    "* Sanity Check passes!!!\n",
    "\n",
    "* Since the observed probability (0.5005) is in the expected 95%CI [0.4959, 0.5041], this matches our expectation. \n",
    "\n",
    "* Sign test (binomial test)also agrees with this conclusion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a470a",
   "metadata": {},
   "source": [
    "## Sanity Check: Click-through-probability (CTP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a984b68",
   "metadata": {},
   "source": [
    "**My thinking process for using Confidence interval to perform sanity check :** \n",
    "    \n",
    "1. The assumption is that the Click-through-probability should be the same in two groups.\n",
    "\n",
    "\n",
    "2. Thus, we can perform the test to see if the difference between two groups is close to zero.\n",
    "\n",
    "\n",
    "3. The strategy is to obtain the 95% confidence interval on the difference. By using this method, we need to use pooled probability to compute the SE for difference.\n",
    "\n",
    "\n",
    "4. The decision-making process is that if this 95%CI of difference includes zero, then sanity check pass!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "036106c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed data:\n",
      "Click-through-probability  Control : 0.082126\n",
      "Click-through-probability  Exp : 0.082182\n",
      "Difference: Control-Exp =  5.6e-05\n"
     ]
    }
   ],
   "source": [
    "# control\n",
    "N_pageviews_Ctrl = df_Ctrl['Pageviews'].sum()\n",
    "N_clicks_Ctrl    = df_Ctrl['Clicks'].sum()\n",
    "CTP_Ctrl         = N_clicks_Ctrl /N_pageviews_Ctrl \n",
    "CTP_Ctrl         = round(CTP_Ctrl, 6)\n",
    "\n",
    "# experiment \n",
    "N_pageviews_Exp  = df_Exp['Pageviews'].sum()\n",
    "N_clicks_Exp     = df_Exp['Clicks'].sum()\n",
    "CTP_Exp          = N_clicks_Exp / N_pageviews_Exp\n",
    "CTP_Exp          = round(CTP_Exp, 6)\n",
    "\n",
    "# difference\n",
    "diff = round(CTP_Exp - CTP_Ctrl, 6)\n",
    "\n",
    "print( \"Observed data:\")\n",
    "print( \"Click-through-probability \", \"Control :\", CTP_Ctrl)\n",
    "print( \"Click-through-probability \", \"Exp :\", CTP_Exp)\n",
    "print( \"Difference:\", \"Control-Exp = \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "442f3269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08215409089789526"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the 95% CI for the difference \n",
    "# Thus, the Two.Group.Differnece's SE  = sqrt( P.pooled * (1-P.pooled)* (1/N.control + 1/N.exp) ) \n",
    "p_pooled = (N_clicks_Ctrl+ N_clicks_Exp ) / (N_pageviews_Ctrl+N_pageviews_Exp)\n",
    "p_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d8940b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006610608156387222"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Two_Group_Diff_SE = math.sqrt( p_pooled * (1-p_pooled) * (1/N_pageviews_Ctrl  + 1/N_pageviews_Exp))\n",
    "Two_Group_Diff_SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67e2e4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0012, 0.0014]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 95% CI for the difference of Click-through-probability between Control and Exp.\n",
    "margin_error = 1.96* Two_Group_Diff_SE\n",
    "CI95_expected = [diff-margin_error, diff+ margin_error]\n",
    "CI95_expected = [round(i,4) for i in CI95_expected]\n",
    "CI95_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4673703",
   "metadata": {},
   "source": [
    "**Sanity Check result for Click-through-probability:**\n",
    "* The sanity check passes! \n",
    "\n",
    "\n",
    "* Since the 95%CI on the \"difference\" of Click-through-probability between Control and Experiment, [-0.0012, 0.0014] , includes zero, we fail to reject the Null. That is, we support that \"Click-through-probability\" has no difference between Control and Exp groups. This is consistent with our expectation.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bdc0fd",
   "metadata": {},
   "source": [
    "### Summary of Sanity Check\n",
    "\n",
    "* Count Metric\n",
    "\n",
    "> **My thinking process for Sign Test (Binomial test) :** \n",
    ">> 1. If the metric is a simple count, then I will use Sign Test (Binomial test) to perform the sanity check. \n",
    ">> 2. The key is to realize each day is an independent trial and the success can be defined as \"Control > Experiment\". \n",
    ">> 3. The assumption is that **page views** should be equally and randomly divided into two groups. Therefore, some days Control group may have more page view than Experiment group, and this chance is expected to be 0.5.\n",
    ">> 4. Then, the \"binomial test\" will test if the observed data match our expectation. In this case, if p-value > 0.05, then this is the statistical evidence to support no difference between two groups.\n",
    "\n",
    "> **My thinking process for using Confidence interval (CI) to perform sanity check :** \n",
    ">> 1. The assumption is that the invariant metric should the same between two groups, so the the ratio of Control to Experiment should be close to 1:1 or we can say p = (N of Control)/(total) is about 0.5.\n",
    ">> 2. The strategy is to obtain the 95% confidence interval (95%CI) on the expected p, given the expected p=0.5 and observed N.\n",
    ">> 3. The decision-making process is that if the observed $\\hat{p}$ is in this 95%CI, then sanity check pass!, because it's acceptable to observe such $\\hat{p}$ at the 95% confidence level.\n",
    "\n",
    "|Metric |Sign-Test p-value |Observed values |95% confidence interval on expected value| Sanity Check Results|\n",
    "|--|--|--|--|--|\n",
    "|Number of cookies (simple count)     |p-value 0.324|0.5006 |[0.4988, 0.5012]| Sign Test and 95%CI check are all good|\n",
    "|Number of clicks (simple count)      |p-value 1.0  |0.5005 |[0.4959, 0.5041]| Sign Test and 95%CI check are all good|\n",
    "\n",
    "\n",
    "* Probability Metric\n",
    "\n",
    "> **My thinking process for using Confidence interval to perform sanity check :**     \n",
    ">> 1. The assumption is that the probability should be the same in two groups.\n",
    ">> 2. Thus, we can test if the difference between two groups is close to zero.\n",
    ">> 3. The strategy is to obtain the 95% confidence interval on the difference. By using this method, we need to use pooled probability to compute the SE for difference.\n",
    ">> 4. The decision-making process is that if this 95%CI of difference includes zero, then sanity check pass!\n",
    "\n",
    "\n",
    "    \n",
    "|Metric |Observed difference |95% confidence interval on difference| Sanity Check Results|\n",
    "|--|--|--|--|\n",
    "|Click-through-probability (probability) |0.000056 |[-0.0012, 0.0014]| Good, because the 95%CI of difference includes zero |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb4ab2",
   "metadata": {},
   "source": [
    "# 6. Effect Size Test and Sign Test\n",
    "Now, it's time use the data to make decision if we should launch this new feature. For each of your evaluation metric, compute a Confidence Interval (CI) around the difference. Explain whether to use Bonferroni correction.\n",
    "\n",
    "\n",
    "**My evaluation metrics:**\n",
    "1. Gross Conversion = enrollment / click \n",
    "2. Net Conversion   = payment / click\n",
    "\n",
    "**Question: Would I use Bonferroni correction?**\n",
    "* **ANS:** No, because these two evaluation metrics are highly corrected, so bonferroni correction will make the test to be too conservative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e30d7b",
   "metadata": {},
   "source": [
    "### Check if sample size is enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27c2f8",
   "metadata": {},
   "source": [
    "Based on previous analysis, we initially aimed for (n = 685,325).  However, in our actual A/B test dataset, the sample size is lower (n_true = 423,525). That is, we may not have enough power to detect true difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "053c47ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423525.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Ctrl.loc[range(0,23), 'Pageviews'].sum() + df_Exp.loc[range(0,23), 'Pageviews'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f0992b",
   "metadata": {},
   "source": [
    "### Two tailed test procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "336956a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_tailed_testing( metric_name, alpha, dmin, expected_direction_of_change ,Ctrl_numerator, Ctrl_denominator, Exp_numerator, Exp_denominator):\n",
    "    import math\n",
    "    from scipy import stats\n",
    "    \n",
    "    Ctrl_p = Ctrl_numerator / Ctrl_denominator\n",
    "    Exp_p = Exp_numerator / Exp_denominator\n",
    "    Diff = Exp_p - Ctrl_p\n",
    "    \n",
    "    P_pooled = (Ctrl_numerator + Exp_numerator ) / (Ctrl_denominator + Exp_denominator)\n",
    "    Diff_SE = math.sqrt(P_pooled*(1-P_pooled)*(1/Ctrl_denominator + 1/Exp_denominator)) \n",
    "    Z_score = stats.norm.ppf(1-alpha/2)\n",
    "    margin_error = Diff_SE * Z_score\n",
    "    Confidence_interval = [Diff - margin_error , Diff + margin_error]\n",
    "    Confidence_interval = [round(i,5) for i in  Confidence_interval]\n",
    "    \n",
    "    #### Result \n",
    "    print(metric_name)\n",
    "    print('Observed Difference: ', round(Diff,5))\n",
    "    print('95% confidence interval on difference: ', Confidence_interval)\n",
    "\n",
    "    #### Check statistical significance\n",
    "    print('\\n')\n",
    "    print('Check Statistical Significance')\n",
    "    if (0 >= Confidence_interval[0]) and (0 <=Confidence_interval[1]) :\n",
    "        print('This interval includes zero, so the difference is \"NOT\" statistically significant.')\n",
    "    else:\n",
    "        print('This confidence interval does not includes zero, so the difference is statistically significant.')  \n",
    "         \n",
    "    #### Check practical significance - two steps \n",
    "    print('\\n')\n",
    "    print('Check Practical Significance')\n",
    "    \n",
    "    #### 1st Step: Check if the direction of difference is expected?\n",
    "    if Diff > 0:\n",
    "        direction = \"positive\"\n",
    "    else:\n",
    "        direction = \"negative\"\n",
    "        \n",
    "    if direction != expected_direction_of_change:\n",
    "        print('The direction of the observed difference is \"Not\" expected, so it is not pratically significant.')\n",
    "        \n",
    "    else:\n",
    "        #### Second Setps: Check if the Confidence interval statisfy the minimal practical difference? \n",
    "        if expected_direction_of_change == 'positive':\n",
    "            if Confidence_interval[0] > dmin:\n",
    "                print (\"The confidence interval is beyond the minimal practical difference, so it is practically significant.\")\n",
    "            else:\n",
    "                print ('it is \"NOT\" practically significant.')\n",
    "        if expected_direction_of_change == 'negative':\n",
    "            if  Confidence_interval[1] < dmin:\n",
    "                print (\"The confidence interval is beyond the minimal practical difference, so it is practically significant.\")\n",
    "            else:\n",
    "                 print ('it is \"NOT\" practically significant.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91db63",
   "metadata": {},
   "source": [
    "#### Two tailed test - [1] Gross Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6920e928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gross Conversion\n",
      "Observed Difference:  -0.02055\n",
      "95% confidence interval on difference:  [-0.02912, -0.01199]\n",
      "\n",
      "\n",
      "Check Statistical Significance\n",
      "This confidence interval does not includes zero, so the difference is statistically significant.\n",
      "\n",
      "\n",
      "Check Practical Significance\n",
      "The confidence interval is beyond the minimal practical difference, so it is practically significant.\n"
     ]
    }
   ],
   "source": [
    "two_tailed_testing(metric_name = 'Gross Conversion',\n",
    "                   alpha=0.05, \n",
    "                   dmin=0.01,\n",
    "                   expected_direction_of_change= 'negative',\n",
    "                   Ctrl_numerator  =df_Ctrl.loc[range(0,23), 'Enrollments'].sum(),\n",
    "                   Ctrl_denominator=df_Ctrl.loc[range(0,23), 'Clicks'     ].sum(), \n",
    "                   Exp_numerator    =df_Exp.loc[range(0,23), 'Enrollments'].sum(), \n",
    "                   Exp_denominator  =df_Exp.loc[range(0,23), 'Clicks'     ].sum()\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974af012",
   "metadata": {},
   "source": [
    "####  Two tailed test - [2] Net Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1ed5baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Conversion\n",
      "Observed Difference:  -0.00487\n",
      "95% confidence interval on difference:  [-0.0116, 0.00186]\n",
      "\n",
      "\n",
      "Check Statistical Significance\n",
      "This interval includes zero, so the difference is \"NOT\" statistically significant.\n",
      "\n",
      "\n",
      "Check Practical Significance\n",
      "The direction of the observed difference is \"Not\" expected, so it is not pratically significant.\n"
     ]
    }
   ],
   "source": [
    "two_tailed_testing(metric_name = 'Net Conversion',\n",
    "                   alpha=0.05, \n",
    "                   dmin=0.0075,\n",
    "                   expected_direction_of_change= 'positive',\n",
    "                   Ctrl_numerator  =df_Ctrl.loc[range(0,23), 'Payments'].sum(),\n",
    "                   Ctrl_denominator=df_Ctrl.loc[range(0,23), 'Clicks'  ].sum(), \n",
    "                   Exp_numerator    =df_Exp.loc[range(0,23), 'Payments'].sum(), \n",
    "                   Exp_denominator  =df_Exp.loc[range(0,23), 'Clicks'  ].sum()\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb10d35",
   "metadata": {},
   "source": [
    "### Sing test procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63ca12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#### Sign Test function ####\n",
    "############################\n",
    "def SingTest(Trials, Successes, Expected_Prob):\n",
    "    from scipy import stats\n",
    "    p_value_SingTest = stats.binom_test(x=Successes, n=Trials, p=Expected_Prob, alternative='two-sided')\n",
    "    \n",
    "    print( \"N_trials: \", N_trials)\n",
    "    print( \"N_success: \", N_success)\n",
    "    print( \"Sign Test (two-sided) P-value: \", round(p_value_SingTest,5)  )\n",
    "\n",
    "    if p_value_SingTest < 0.05:\n",
    "        print('Test Result: Statistically significant.')\n",
    "    else:\n",
    "        print('Test Result: Not statistically significant.')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd65dc",
   "metadata": {},
   "source": [
    "#### Sign Test - [1] Gross Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94762bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_trials:  23\n",
      "N_success:  19\n",
      "Sign Test (two-sided) P-value:  0.0026\n",
      "Test Result: Statistically significant.\n"
     ]
    }
   ],
   "source": [
    "N_trials     = len( df_Ctrl.loc[range(0,23), 'Enrollments'] )\n",
    "Ctrl_P_array = df_Ctrl.loc[range(0,23), 'Enrollments'] / df_Ctrl.loc[range(0,23), 'Clicks']\n",
    "Exp_P_array  = df_Exp.loc[range(0,23), 'Enrollments'] / df_Exp.loc[range(0,23), 'Clicks']\n",
    "N_success    = sum( Ctrl_P_array> Exp_P_array)\n",
    "\n",
    "SingTest(Trials= N_trials,\n",
    "         Successes= N_success,\n",
    "         Expected_Prob = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191c040",
   "metadata": {},
   "source": [
    "#### Sign Test - [2] Net Conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58b9f44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_trials:  23\n",
      "N_success:  13\n",
      "Sign Test (two-sided) P-value:  0.67764\n",
      "Test Result: Not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "N_trials = len( df_Ctrl.loc[range(0,23), 'Payments'] )\n",
    "Ctrl_P_array = df_Ctrl.loc[range(0,23), 'Payments'] / df_Ctrl.loc[range(0,23), 'Clicks']\n",
    "Exp_P_array =  df_Exp.loc[range(0,23), 'Payments'] / df_Exp.loc[range(0,23), 'Clicks']\n",
    "N_success = sum( Ctrl_P_array> Exp_P_array)\n",
    "\n",
    "SingTest(Trials= N_trials,\n",
    "         Successes= N_success,\n",
    "         Expected_Prob = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42afbf96",
   "metadata": {},
   "source": [
    "# 7. Results Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c49cc3",
   "metadata": {},
   "source": [
    "|Evaluation Metric| Observed Difference| Minimal Practical Significance (dmin)| 95% Confidence Interval on Diff.|Statistical Significance?| Practical Significance?| Sign Test - Statistical Significance?| Final Comment|\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|Gross Conversion (enrollment/click)|-0.02055|-0.01|[-0.0291, -0.0120]|Yes |Yes |Yes| All good|\n",
    "|Net Conversion (payment/click)|-0.00487|+0.0075|[-0.0116, 0.0019]|No |No, because the difference is negative which is not our expectation |No| Not good|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70102fa0",
   "metadata": {},
   "source": [
    "* Gross conversion satisfied all of the tests, suggesting that the new feature can reduce the amount of people in the enrollment stage.  \n",
    "\n",
    "* However, net conversion did not pass the test, meaning that this new feature won't increase the probability of making the payment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e72a1d",
   "metadata": {},
   "source": [
    "# 8. Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fbc16f",
   "metadata": {},
   "source": [
    "* Since our evaluation metrics did not pass all tests, I will not launch this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb738c4e",
   "metadata": {},
   "source": [
    "# 9. Follow-up Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642ceba0",
   "metadata": {},
   "source": [
    "#### This is my idea-1:\n",
    "> **Hypothesis:** \n",
    "> * Users don't have enough support to go through assignments or lectures\n",
    "\n",
    "> **Experiment:**\n",
    "> * Create a forum which has clear and specific section for each lecture and assignment, so users can easily have resources easily to go through the course.\n",
    "\n",
    "> **Expectation and Evaluation Metric**\n",
    "> * If the hypothesis is true, then we should see a **higher Net Conversion** in Experiment Group, compared to Control Group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab911884",
   "metadata": {},
   "source": [
    "#### This is my idea-2:\n",
    "> **Hypothesis:** \n",
    "> * Users just lost the motivation over time.\n",
    "\n",
    "> **Experiment:**\n",
    "> * For users already in the free-trial, when they click \"cancel\" the enrollment, system will ask the user about the advantage of taking this course. If users still want to cancel it, then they can drop from the free trial.  \n",
    "\n",
    "> **Expectation and Evaluation Metric**\n",
    "> * If the hypothesis is true, then we should see a **higher Net Conversion** in Experiment Group, compared to Control Group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873386a",
   "metadata": {},
   "source": [
    "#### Another good idea based on this post: \n",
    "https://zacks.one/udacity-a-b-testing-by-google/#Follow-Up-Experiment-How-to-Reduce-Early-Cancellations\n",
    "\n",
    "> **Hypothesis:** \n",
    "> * Users don't have enough pre-requisite courses.\n",
    "\n",
    "> **Experiment:**\n",
    "> * After user click \"Start Free Trial\", we can ask if users have enough pre-requisite knowledge. If not, users will be diverted to the pre-requisite courses. If yes, then users will enroll in the free trial for 14 days.\n",
    "\n",
    "> **Expectation and Evaluation Metric**\n",
    "> * If the hypothesis is true, then we should see a **lower Gross Conversion** but a **higher Net Conversion** in Experiment Group, compared to Control Group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88aeeb1",
   "metadata": {},
   "source": [
    "## 10. Resources\n",
    "These are the solutions made by other people who complete this project:\n",
    "* solution-1: https://nancyyanyu.github.io/posts/8fdfc10f/#more\n",
    "> Solution Author contact information - https://github.com/nancyyanyu\n",
    "\n",
    "* solution-2: https://github.com/shubhamlal11/Udacity-AB-Testing-Final-Project \n",
    "* solution-3: https://www.kaggle.com/code/mariusmesserschmied/udacity-a-b-testing-final-course-project/notebook\n",
    "* soluiton-4: https://zacks.one/udacity-a-b-testing-by-google/#Familywise-Error-Rate-FWER\n",
    "* solution-5: https://towardsdatascience.com/a-b-testing-part-2-42b94e1fb1dc\n",
    "* solution-6: https://www.xueni.me/2020-07-05-udacity-ab-testing-final-project/\n",
    "* solution-7: https://rstudio-pubs-static.s3.amazonaws.com/347758_9da9522d18a8455fb810c48b11ff9824.html#3measure_of_variability\n",
    "* solution-8: https://medium.com/@zhouyuchen999/a-b-testing-experiment-a-udacity-course-project-f958f7236278"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
